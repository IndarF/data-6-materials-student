{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 6: Web Scraping with Beautiful Soup\n",
    "\n",
    "Based on lessons by [Melanie Walsh's _Intro to Cultural Analytics](https://melaniewalsh.github.io/Intro-Cultural-Analytics), [Alison Parrish](http://www.decontextualize.com/) and [Jinho Choi](https://github.com/emory-courses/data-science/blob/master/course/data_aggregation/data_aggregation.ipynb)\n",
    "\n",
    "# Inspecting HTML's anatomy with Developer Tools\n",
    "\n",
    "Thanks to Alison Parrish, we have a very simple example of HTML to begin with. It is about kittens. [Here's the rendered version](http://static.decontextualize.com/kittens.html), and [here's the HTML source code](https://raw.githubusercontent.com/ledeprogram/courses/master/databases/data/kittens.html).\n",
    "\n",
    "## Developer Tools in your browser\n",
    "First we're going to use Developer Tools in Chrome to take a look at how `kittens.html` is organized. Click on the \"rendered ve#rsion\" link above.\n",
    "* Chrome, Firefox: Right-click (or ctrl-click) anywhere on the page, then click \"Inspect\"\n",
    "* Safari: Right-click (or ctrl-click) anywhere on the page, then click \"Inspect Element\"\n",
    "\n",
    "This will the browser's Chrome's Developer Tools. Your screen should look (something) like this:\n",
    "\n",
    "<a href=\"http://static.decontextualize.com/snaps/kittens-dev-tools.png\"><img src=\"http://static.decontextualize.com/snaps/kittens-dev-tools.png\" alt=\"kittens-dev-tools\"/></a>\n",
    "\n",
    "In the upper panel, you see the web page you're inspecting. In the lower panel, you see a version of the HTML source code, with little arrows next to some of the lines. (The little arrows allow you to collapse parts of the HTML source that are hierarchically related.) As you move your mouse over the elements in the top panel, different parts of the source code will be highlighted. Chrome is showing you which parts of the source code are causing which parts of the page to show up. Pretty spiffy!\n",
    "\n",
    "This relationship also works in reverse: you can move your mouse over some part of the source code in the lower panel, which will highlight in the top panel what that source code corresponds to on the page. We'll be using this later to visually identify the parts of the page that are interesting to us, so we can write code that extracts the contents of those parts automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## The structure of `kittens.html`\n",
    "\n",
    "Here's what the source code of kittens.html looks like:\n",
    "\n",
    "```\n",
    "<!doctype html>\n",
    "<html>\n",
    "  <head>\n",
    "    <title>Kittens!</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <h1>Kittens and the TV Shows They Love</h1>\n",
    "    <div class=\"kitten\">\n",
    "      <h2>Fluffy</h2>\n",
    "      <div><img src=\"http://placekitten.com/100/100\"></div>\n",
    "      <ul class=\"tvshows\">\n",
    "        <li><a href=\"http://www.imdb.com/title/tt0106145/\">Deep Space Nine</a></li>\n",
    "        <li><a href=\"http://www.imdb.com/title/tt0088576/\">Mr. Belvedere</a></li>\n",
    "      </ul>\n",
    "      Last check-up: <span class=\"lastcheckup\">2014-01-17</span>\n",
    "    </div>\n",
    "    <div class=\"kitten\">\n",
    "      <h2>Monsieur Whiskeurs</h2>\n",
    "      <div><img src=\"http://placekitten.com/150/100\"></div>\n",
    "      <ul class=\"tvshows\">\n",
    "        <li><a href=\"http://www.imdb.com/title/tt0106179/\">The X-Files</a></li>\n",
    "        <li><a href=\"http://www.imdb.com/title/tt0098800/\">Fresh Prince</a></li>\n",
    "      </ul>\n",
    "      Last check-up: <span class=\"lastcheckup\">2013-11-02</span>\n",
    "    </div>\n",
    "  </body>\n",
    "</html>\n",
    "```\n",
    "\n",
    "This is pretty well organized HTML, but if you don't know how to read HTML, it will still look like a big jumble. Here's how I would characterize the structure of this HTML, reading in my own idea of what the meaning of the elements are.\n",
    "\n",
    "* We have two \"kittens,\" both of which are contained in `<div>` tags with class `kitten`.\n",
    "* Each \"kitten\" `<div>` has an `<h2>` tag with that kitten's name.\n",
    "* There's an image for each kitten, specified with an `<img>` tag.\n",
    "* Each kitten has a list (a `<ul>` with class `tvshows`) of television shows, contained within `<li>` tags.\n",
    "* Those list items themselves have links (`<a>` tags) with an `href` attribute that contains a link to an IMDB entry for that show."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: HTML Elements\n",
    "\n",
    "In summary, HTML is composed of **HTML elements**, which have:\n",
    "\n",
    "* **Tags**, provided as the first string within angled brackets.\n",
    "* (optional) **attributes**, provided as `attr=value` key-value pairs within the angled brackets.\n",
    "* (optional) a string and/or other elements under the tag. These will be between the matching angled brackets, e.g., `<li>` and `</li>`.\n",
    "\n",
    "You will hear **tag** and **element** used interchangeably. This is because every **HTML element must have a tag.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TASK**: Discussion\n",
    "\n",
    "1. What's the parent tag of `<a href=\"http://www.imdb.com/title/tt0088576/\">Mr. Belvedere</a>`? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Both `<div class=\"kitten\">` tags share a parent tag---what is it? What attributes are present on both `<img>` tags?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping and Web requests\n",
    "\n",
    "We've examined `kittens.html` a bit now. What we'd like to do is write some code that is going to extract information from the HTML, like \"what is the last checkup date for each of these kittens?\" or \"what are Monsieur Whiskeur's favorite TV shows?\" To do so, we need to:\n",
    "\n",
    "1. **Scrape** the HTML from the internet\n",
    "2. **Parse** the HTML by creating a representation of it in our program that we can manipulate with Python\n",
    "\n",
    "Let's do the first task: **scraping**. It's left to us to actually *get* the HTML from somewhere. In most cases, we'll want to download the HTML directly from the actual web. For that, we'll use the `get` method from the Python library `requests` ([link](https://2.python-requests.org/en/master/)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's import the requests library\n",
    "import requests "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it worked, you won't get an error message.\n",
    "\n",
    "Now let's use the \"get\" method to make an http request (the eponymous \"requests\") to get the contents of kittens.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = requests.get(\"http://static.decontextualize.com/kittens.html\") \n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that \"resp\" is a **Python object**, and not plain text. The HTTP Response Status Code 200 means \"OK\"---as in, the webpage was able to give us the data we wanted.\n",
    "\n",
    "_Side note_: The \"get\" method makes things easy by guessing at the document's character encoding. We're not really going to talk about character encoding until next class, but since we can, let's check this page's encoding real quick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp.encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, back on task. Now let's create a **string** with the contents of the web page in text format we use the \"text\" method for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_str = resp.text\n",
    "html_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks like a mess but it's apparent that we've obtained the data as desired.\n",
    "\n",
    "If we wanted to \"pretty print\", note that the `html_str` has a lot of whitespace:\n",
    "* `\\t`: Tab\n",
    "* `\\n`: Newline\n",
    "\n",
    "Calling `print` will render this whitespace in our display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretty print\n",
    "print(html_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Why is web scraping hard?\n",
    "\n",
    "It turns out that web scraping is heavily restricted on today's internet. What do you think are reasons why websites would **not** want programs periodically scraping their data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this class, we will usually handle the web requests and scraping for you. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Beautiful Soup library\n",
    "\n",
    "Now, onto the next step:\n",
    "\n",
    "> 2. Parse the HTML by creating a representation of it in our program that we can manipulate with Python.\n",
    "\n",
    "What representation should we choose? As mentioned earlier, HTML is hard to parse by hand. (Don't even try it. In particular, [don't parse HTML with regular expressions](http://stackoverflow.com/a/1732454).)\n",
    "\n",
    "**[Beautiful Soup](http://www.crummy.com/software/BeautifulSoup/)** is a Python library that parses (even poorly formatted) HTML and allows us to extract and manipulate its contents. More specifically, it gives us some Python objects that we can call methods on to poke at the data contained therein. So instead of working with strings and bytes, we can work with Python objects, methods and data structures.\n",
    "\n",
    "Note that BeautifulSoup can parse any HTML that is provided as a string. We've already gotten an HTML string from our previous web request, so now we need to create a Beautiful Soup object from that data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "document = BeautifulSoup(html_str, \"html.parser\")\n",
    "type(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `BeautifulSoup` function creates a new Beautiful Soup object. It takes two parameters: the string containing the HTML data, and a string that designates which underlying parser to use to build the parsed version of the document. (Leave this as `\"html.parser\"`.) I've assigned this object to the variable `document`.\n",
    "\n",
    "The `document` object supports a number of interesting methods that allow us to dig into the contents of the HTML. Primarily what we'll be working with are:\n",
    "* `Tag` objects, and\n",
    "* `ResultSet` objects, which are essentially just lists of `Tag` objects.\n",
    "\n",
    "## Finding a tag with `find`\n",
    "\n",
    "As we've previously discussed, HTML documents are composed of tags. To represent this, Beautiful Soup has a type of value that represents tags. We can use the `.find()` method of the `BeautifulSoup` object to find a tag that matches a particular tag name. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_tag = document.find('h1')\n",
    "type(h1_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `Tag` object has several interesting attributes and methods. The `string` attribute of a `Tag` object, for example, returns a string representing that tag's contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_tag.string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access the attributes of a tag by treating the tag object as though it were a **dictionary**. To get the **value** associated with a particular **attribute**. Use the square-bracket syntax, providing the attribute name as key/string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the `src` attribute of the first `<img>` tag in the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tag = document.find('img')\n",
    "img_tag['src']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: You might have noticed that there is more than one `<img>` tag in `kittens.html`! If more than one tag matches the name you pass to `.find()`, it returns only the first matching tag. (A better name for `.find()` might be `.find_first()`, but we digress.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TASK**: Find the last check-up date of the first kitten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR SOLUTION HERE\n",
    "tag = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding multiple tags with `find_all`\n",
    "\n",
    "It's very often the case that we want to find not just one tag that matches particular criteria, but ALL tags matching those criteria. For that, we use the `.find_all()` method of the `BeautifulSoup` object. For example, to find all `h2` tags in the document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2_tags = document.find_all('h2')\n",
    "type(h2_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what's in the Result Set?\n",
    "\n",
    "In order to find out, we're going to need to use a loop. Specifically, a **for** loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in h2_tags:\n",
    "    print(tag.string) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This conveniently gives you a variable, `tag`, that updates with the appropriate value each time you iterate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding tags with particular attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In any case, both the `.find()` and `.find_all()` methods can search not just for tags with particular names, but also for **tags that have particular attributes**.\n",
    "\n",
    "For that, we use the **optional** `attrs` keyword argument. `attrs` is a dictionary that associates attribute names as keys and the desired attribute value as values.\n",
    "\n",
    "```\n",
    "document.find_all(tag_name, attrs=None)\n",
    "```\n",
    "\n",
    "To find all `span` tags with a `class` attribute of `lastcheckup`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkup_tags = document.find_all('span', attrs={'class': 'lastcheckup'})\n",
    "for tag in checkup_tags:\n",
    "    print(tag.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More on BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before we move on:**\n",
    "\n",
    "Beautiful Soup's `.find()` and `.find_all()` methods are actually more powerful than we're letting on here. [Check out the details in the official Beautiful Soup documentation.](http://www.crummy.com/software/BeautifulSoup/bs4/doc/#find-all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use `find`/`find_all` on tags, too\n",
    "\n",
    "Let's say that we wanted to print out a list of the name of each kitten, along with a list of the names of that kitten's favorite TV shows. In other words, we want to print out something that looks like this:\n",
    "\n",
    "    Flufzfy: Deep Space Nine, Mr. Belvedere\n",
    "    Monsieur Whiskeurs: The X-Files, Fresh Prince\n",
    "    \n",
    "In order to do this, we need to find *not just* tags with particular names, but tags with **particular hierarchical relationships** with other tags:\n",
    "\n",
    "1. Identify all of the kittens, then\n",
    "1. Find the shows that belong to that kitten.\n",
    "\n",
    "This kind of search is made easy by the fact that you can use `.find()` and `.find_all()` methods not just on the entire document, but on **individual tags***. When you use these methods on tags, they search for matching tags that are specifically **children of** the tag that you call them on.\n",
    "\n",
    "---\n",
    "\n",
    "In our kittens example, we can see that information about individual kittens is grouped together under `<div>` tags with a `class` attribute of `kitten`. So, to find a list of all `<div>` tags with `class` set to `kitten`, we might do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "kitten_tags = document.find_all(\"div\", attrs={\"class\": \"kitten\"})\n",
    "# kitten_tags # uncomment if you want to print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll loop over that list of tags and find, inside each of them, the `<h2>` tag that is its child:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "for kitten_tag in kitten_tags:\n",
    "    h2_tag = kitten_tag.find('h2')\n",
    "    print(h2_tag.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String method demo practice\n",
    "\n",
    "Now, we'll go one extra step. Looping over all of the kitten tags, we'll find not just the `<h2>` tag with the kitten's name, but all `<a>` tags (which contain the names of the TV shows that we were looking for).\n",
    "\n",
    "_Note*: The list method `lst.append(elt)` returns nothing and directly modifies the original list `lst`, appending `elt` to the end. (This behavior is unlike `np.append`, which returns a new array.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trace through this code carefully!\n",
    "\n",
    "for kitten_tag in kitten_tags:\n",
    "    h2_tag = kitten_tag.find('h2')\n",
    "    \n",
    "    a_tag_strings = []\n",
    "    for tag in kitten_tag.find_all('a'):\n",
    "        a_tag_strings.append(tag.string)\n",
    "        \n",
    "    print(h2_tag.string + \":\", \", \".join(a_tag_strings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Find last check-up for all kittens\n",
    "\n",
    "Using the code above as a template, write code that prints out a list of kitten names along with the last check-up date for that kitten.\n",
    "\n",
    "HINT: Look up above for the HTML that deals with check-up dates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Click for Solution</summary>\n",
    "\n",
    "Various options. One reasonable approach:\n",
    "\n",
    "```\n",
    "for kitten_tag in kitten_tags:\n",
    "    h2_tag = kitten_tag.find('h2') # keep this to find the kittens\n",
    "    checkup_tag = kitten_tag.find('span', attrs={'class': 'lastcheckup'})\n",
    "\n",
    "    print(h2_tag.string + \", \" + checkup_tag.string)\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Find links to all kittens' favorite shows\n",
    "\n",
    "Using the code above, write code that prints a list of kitten names with links to that kitten's favorite shows. I.e., you should end up with something of the format:\n",
    "\n",
    "`Name: [kitten name]\n",
    " URLS: www.asdasdsa.com, www.sdkalskdjsa.com`\n",
    " \n",
    "Hint: Look up above for how you access the attribute of a tag. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Click for Solution</summary>\n",
    "\n",
    "Various options. One reasonable approach:\n",
    "\n",
    "```\n",
    "for kitten_tag in kitten_tags:\n",
    "    h2_tag = kitten_tag.find('h2') # keep this to find the kittens\n",
    "    url_strings = []\n",
    "    for url in kitten_tag.find_all('a'):\n",
    "        url_strings.append(url['href'])\n",
    "    urls_joined = \", \".join(url_strings)\n",
    "    print(\"Name: \" + h2_tag.string)\n",
    "    print(\"URLs: \" + urls_joined)\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find sibling tags: `find_next_sibling()`\n",
    "\n",
    "Often, the tags we're looking for don't have a distinguishing characteristic, like a `class` attribute, that allows us to find them using `.find()` and `.find_all()`, and the tags also aren't in a parent-child relationship. This can be tricky! Take the following HTML snippet, for example:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cheese_html = \"\"\"\n",
    "<h2>Camembert</h2>\n",
    "<p>A soft cheese made in the Camembert region of France.</p>\n",
    "\n",
    "<h2>Cheddar</h2>\n",
    "<p>A yellow cheese made in the Cheddar region of... France, probably, idk whatevs.</p>\n",
    "\"\"\"\n",
    "\n",
    "cheese_document = BeautifulSoup(cheese_html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If our task was to create a list of the name of the cheese followed by the description that follows in the `<p>` tag directly afterward, we'd be out of luck. Fortunately, Beautiful Soup has a `.find_next_sibling()` method, which allows us to search for the next tag that is a *sibling* of the tag you're calling it on (i.e., the two tags share a parent), that also matches particular criteria. So, for example, to accomplish the task outlined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cheese_dict = {}\n",
    "for h2_tag in cheese_document.find_all('h2'):\n",
    "    cheese_name = h2_tag.string\n",
    "    cheese_desc_tag = h2_tag.find_next_sibling('p')\n",
    "    cheese_dict[cheese_name] = cheese_desc_tag.string\n",
    "\n",
    "cheese_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Beautiful Soup Bugs\n",
    "\n",
    "You now know most of what you need to know to scrape web pages effectively. Good job!\n",
    "\n",
    "But before you're done, we should talk about what to do when things go wrong.\n",
    "\n",
    "A number of things might go wrong with Beautiful Soup. Here are just a few."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag does not exist with `find`\n",
    "\n",
    "You might, for example, search for a tag that doesn't exist in the document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "footer_tag = document.find(\"footer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful Soup doesn't return an error if it can't find the tag you want. Instead, it returns `None`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(footer_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you try to call a method on the object that Beautiful Soup returned anyway, you might end up with an error like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "footer_tag.find(\"p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might also inadvertently try to get an attribute of a tag that wasn't actually found. You'll get a similar error in that case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "footer_tag['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever you see something like `TypeError: 'NoneType' object is not subscriptable`, it's a good idea to check to see whether your method calls are indeed finding the thing you were looking for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No tags exist with `find_all`\n",
    "\n",
    "The `.find_all()` method will return an empty list if it doesn't find any of the tags you wanted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "footer_tags = document.find_all(\"footer\")\n",
    "print(footer_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you attempt to access one of the elements of this regardless..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(footer_tags[0].string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...you'll get an `IndexError`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Out-of-scope material] List comprehension\n",
    "\n",
    "Consider the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkup_tags = document.find_all('span', attrs={'class': 'lastcheckup'})\n",
    "[tag.string for tag in checkup_tags]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The second line in the code cell above is a helpful shorthand: it creates a list with each of the `tag.string`s in `checkup_tags`.\n",
    "\n",
    "In more official terms, it's called a *list comprehension*, and it helps with a very common task in both data analysis and computer programming: when you want to apply an operation to every item in a list (e.g., scaling the numbers in a list by a fixed factor), or create a copy of a list with only those items that match a particular criterion (e.g., eliminating values that fall below a certain threshold). \n",
    "\n",
    "A list comprehension has a few parts:\n",
    "\n",
    "* a source list, or the list whose values will be transformed or filtered;\n",
    "* a predicate expression, to be evaluated for every item in the list;\n",
    "* (optionally) a membership expression that determines whether or not an item in the source list will be included in the result of evaluating the list comprehension, based on whether the expression evaluates to True or False; and\n",
    "* a temporary variable name by which each value from the source list will be known in the predicate expression and membership expression.\n",
    "These parts are arranged like so:\n",
    "\n",
    "> `[` *predicate expression* `for` *temporary variable name* `in` *source list* `if` *membership expression* `]`\n",
    "\n",
    "The words for, in, and if are a part of the syntax of the expression. They don't mean anything in particular (and in fact, they do completely different things in other parts of the Python language). You just have to spell them right and put them in the right place in order for the list comprehension to work.\n",
    "\n",
    "You are welcome to use list comprehension in this course, but we won't test it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further reading\n",
    "\n",
    "* [Chapter 11](https://automatetheboringstuff.com/chapter11/) from Al Sweigart's [Automate the Boring Stuff with Python](https://automatetheboringstuff.com/) is another good take on this material (and discusses a wider range of techniques).\n",
    "* [The official Beautiful Soup documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) provides a systematic walkthrough of the library's functionality. If you find yourself thinking, \"it really should be easy to do the thing that I want to do, why isn't it easier?\" then check the documentation! Leonard's probably already thought of a way to make it easier and implemented a feature in the code to help you out.\n",
    "* Beautiful Soup is the best scraping library out there for quick jobs, but if you have a larger site that you need to scrape, you might look into [Scrapy](http://scrapy.org/), which bundles a good parser with a framework for writing web \"spiders\" (i.e., programs that parse web pages and follow the links found there, in order to make a catalog of an entire web site, not just a single web page)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
