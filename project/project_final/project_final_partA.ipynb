{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ede69ab0-dd24-4f17-b9b9-91c1dffea462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell, don't change anything.\n",
    "from datascience import *\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bc1619-4ac6-4d0f-b02f-45e21ca861cf",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "\n",
    "# Project Part A: Introduction\n",
    "\n",
    "The full specification for this project is in Google Docs:\n",
    "* [Final Project: Part A](https://docs.google.com/document/d/11fLAJmCwJT55pWUVhHQQ2YXkPtPcGrH7Bmn0DBWM85M/edit?usp=sharing)\n",
    "\n",
    "The full description of each dataset is in Google Docs:\n",
    "* [CSS Tasks](https://docs.google.com/document/d/1gWbpm0qHUWHySuj9rq2gl1CvN9BgcQDUQLTl2hYLlsk/edit?usp=sharing)\n",
    "\n",
    "This Jupyter notebook contains code cells that should accompany your Final Project Part A PDF submission. You should submit this notebook (and associated files)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f97df09-c92d-4cd2-800e-ee97ec820d59",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "\n",
    "# Part 1: Pick Your Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02590e7-90b7-4476-a858-4728749f9d68",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 1: Task Shortname\n",
    "\n",
    "**Read the full description of this task in the Google Doc.** What follows in this part of the notebook is a guide for how to explore dataset files.\n",
    "\n",
    "All datasets are in the `datasets` subdirectory: `project/project_final/datasets`. Navigate to this directory using the file explorer on DataHub. See [the Google Doc](https://docs.google.com/document/d/11fLAJmCwJT55pWUVhHQQ2YXkPtPcGrH7Bmn0DBWM85M/edit?tab=t.0#heading=h.jd8217fhrqlu) for details.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14876540-55f4-4935-84df-f40a963e0a63",
   "metadata": {},
   "source": [
    "### Option 1: Look at the data with `datascience` library\n",
    "    \n",
    "To load in, say, `emotion.csv` into a `datascience` Table, first construct a file path as a string with this subdirectory, separated by forwardslashes:\n",
    "\n",
    "```\n",
    "csv_fname = \"datasets/emotion.csv\"\n",
    "```\n",
    "\n",
    "Then you can load this in as usual to a datascience Table. See below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6aca107-bf56-4d68-bad4-a596fe022b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>index</th> <th>text</th> <th>emotions</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>350001</td> <td>i feel so horny byou said as he put his arms around ruki ...</td> <td>love    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>350002</td> <td>i will post what i actually did and just a review of eve ...</td> <td>love    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>350003</td> <td>im still reflecting on the day and what it meant to be t ...</td> <td>joy     </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (66805 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "csv_fname = \"datasets/emotion.csv\" # replace this line\n",
    "\n",
    "table = Table.read_table(csv_fname)\n",
    "table.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f79b2fb-c050-4135-955a-f63a6045f52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here for exploring data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3214b9-c682-49b0-b2df-502834846012",
   "metadata": {},
   "source": [
    "### Option 2: Look at the data with a spreadsheets program\n",
    "\n",
    "You can also download this CSV and import into your spreadsheet program of choice, e.g., Google Spreadsheets or Microsoft Excel.\n",
    "\n",
    "To download the CSV file, go to the file in the DataHub file explorer (sidebar). Right click --> Download."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fa664e-d523-4f6c-8fb4-174a56f3ea70",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "\n",
    "# Part 2: Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b7f8d5-dddc-4c2e-819d-cd3f88f38912",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 2: Contextual Analysis\n",
    "\n",
    "No code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8712afae-fd6f-487c-8901-c03a9fec338c",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 3: Explore the CSV\n",
    "\n",
    "Feel free to use the cell below to explore your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8b5d0bf-a479-41e0-8704-6b41aa104935",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_fname = \"datasets/emotion.csv\" # replace this line\n",
    "\n",
    "table = Table.read_table(csv_fname)\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6475562e-8234-4a66-a417-e76c9d652db1",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 4: Distribution of \"Human Gold Labels\"\n",
    "\n",
    "---\n",
    "\n",
    "### Question 4a\n",
    "\n",
    "Write code that visualizes the distribution of labels in your dataset. Depending on how many sets of labels you have, you may need to produce multiple visualizations.\n",
    "\n",
    "In the cell below, write code that produces this visualization.\n",
    "* You should use the datascience library and associated visualization methods in this course.\n",
    "* Your analysis should be on `<shortname>.csv`, where `<shortname>` is the shortname of your CSS task. Do not look at `<shortname>_train.csv` nor `<shortname>_val_uncoded.csv`; these are used for the next part.\n",
    "\n",
    "In your Google Doc report, include screenshot(s) of the resulting visualization(s). You do not need to screenshot your code; writing your code in the cell below is sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5231a5cb-9850-43b1-aec1-17279e547624",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_fname = \"datasets/emotion.csv\" # replace this line\n",
    "\n",
    "table = Table.read_table(csv_fname)\n",
    "\n",
    "# your code here for producing a visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c52d94-dcf8-4f55-8790-746c894dfc92",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 5: Distribution of Text "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3e5fe4-aaf6-4c6e-affd-96d3908b38e9",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Question 5a\n",
    "\n",
    "Write code that reports the top 20 most frequent words in your dataset, across all sentences, **ignoring stop words**.\n",
    "\n",
    "**Hints/recommendations**:\n",
    "    \n",
    "* This question is intentionally open-ended.\n",
    "* We’ve imported the stopwords package for you above.\n",
    "* A reasonable solution will use some sort of dictionary.\n",
    "    * Look at the bag of words model that you constructed in a previous project. Translate that approach to this application.\n",
    "    * If you want to challenge yourself, we recommend you look at the CountVectorizer library in the sklearn documentation.\n",
    "* It is alright to use Generative AI for this question, but you will be expected to understand your approach. Depending on your approach, during grading we may ask you follow-up questions about your code.\n",
    "\n",
    "---\n",
    "\n",
    "#### [Tutorial] Helper code\n",
    "    \n",
    "The cell to write your code is listed at the very end of this question. Before that, we have a few helper cells to get you going."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d5e246-36c4-4fcc-913d-ba5970f2fd4d",
   "metadata": {},
   "source": [
    "**Stop words**: The below cells install the `stop_words` package and provide an example of usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9f8974-c8e8-4c62-9b1b-46821b06ecc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stop-words\n",
      "  Using cached stop_words-2025.11.4-py3-none-any.whl.metadata (14 kB)\n",
      "Using cached stop_words-2025.11.4-py3-none-any.whl (59 kB)\n",
      "Installing collected packages: stop-words\n",
      "Successfully installed stop-words-2025.11.4\n"
     ]
    }
   ],
   "source": [
    "# just run this cell\n",
    "!pip install stop-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d6218dc-e2aa-4bf1-a350-8f64a3220595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mz', 'appreciate', 'this', 'yes', 'qv'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just run this cell\n",
    "\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "# Get English stop words\n",
    "stop_words = get_stop_words('english')\n",
    "\n",
    "# five random words\n",
    "Table().with_columns(\"word\", stop_words).sample(5).column(\"word\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fdb1f4-6a2f-4d34-bc1d-c9379bd9f45b",
   "metadata": {},
   "source": [
    "**Split by whitespace**: Depending on your dataset, you may find it useful to go beyond the `split` method we gave you in class. The following cell uses regular expressions (not covered in this course) to take some text and split it based on all non-alphanumeric characters. Feel free to use it.\n",
    "\n",
    "_Note_: Empty strings should not be considered in your solution—you should look at the example below for behavior with non alphanumeric symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e42492c6-5258-41f4-91dd-2efc3d8a9952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'scotus', 'rules', 'they', 'can', 'rule', 'anything', 'they', 'damn', 'well', 'please', 'regardless', 'of', 'we', 'the', 'people', 'welcome', 'to', 'tyranny', 'usa', 'semst', '']\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "# just run this cell\n",
    "import re\n",
    "def split_into_words(any_chunk_of_text):\n",
    "    lowercase_text = any_chunk_of_text.lower()\n",
    "    split_words = re.split(\"\\W+\", lowercase_text)\n",
    "    return split_words \n",
    "\n",
    "example_text = \"#SCOTUS rules they can rule anything they damn well please, regardless of We The People. Welcome to #tyranny.   #USA #SemST!\"\n",
    "example_words = split_into_words(example_text)\n",
    "print(example_words)\n",
    "print(len(example_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a62578-40a6-4c71-b90f-00883bfce5a6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Complete Question 5a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05147085-e0c9-46f9-bd95-d7f4c207bff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a2ceca-a444-43e1-89c0-8ba24e7d206a",
   "metadata": {},
   "source": [
    "\n",
    "In your Google Doc report, list the top 20 words (ignoring stop words) across your text data, sorted by most common first. You do not need to screenshot your code; writing your code in the provided cell of this notebook is sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5815fe-1940-45a7-bf51-85c01fa90d90",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "\n",
    "# Part 3: Hand-coding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b5fce1-2091-4110-98e0-3014cdf45bc9",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 6: Develop Coding Strategy\n",
    "\n",
    "No code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109d106d-c1b0-4b51-afcb-198f5caaf5e4",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 7: Hand-code your data\n",
    "\n",
    "**Read the full description of this task in the Google Doc.** What follows in this part of the notebook is a guide for how to upload your codes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8397677a-b6bb-480d-b296-60f522ce447b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Option 1: Make a `datascience` Table and save it\n",
    "\n",
    "This cell does the following:\n",
    "1. Load in the data from `<shortname>_val_uncoded.csv` and assign to `table_val`.\n",
    "1. Make two new arrays with human codes, `humanA_arr` and `humanB_arr`.\n",
    "1. Add these two columns to `table_val` and call the columns `humanA` and `humanB`, respectively.\n",
    "1. Call `table_val.to_csv(fname)` that **exports** the table to the specified `fname` path. Here, we've named `fname` to `<shortname>_val_human.csv`, but you should replace `<shortname>` with your task shortname, e.g., `emotion_val_human.csv`.\n",
    "\n",
    "This strategy will be very useful for Part B of the project, when you assign many AI code labels. For now, it will seem a bit tedious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "338c355e-6416-4da9-8e97-d62676accd83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datascience import *\n",
    "table_val = Table.read_table(\"datasets/emotion_val_uncoded.csv\") # edit this line\n",
    "table_val.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0229bcb-97e3-4f44-9064-6c37e0a35047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to change this code as you see fit\n",
    "\n",
    "table_val = Table.read_table(\"datasets/emotion_val_uncoded.csv\") # edit this line\n",
    "\n",
    "humanA_arr = [0] * 30 # replace this line with Person A's human-coded labels\n",
    "humanB_arr = [0] * 30 # replace this line with Person B's human-coded labels\n",
    "\n",
    "table_val = table_val.with_columns(\n",
    "                \"humanA\", humanA_arr,\n",
    "                \"humanB\", humanB_arr)\n",
    "\n",
    "fname = \"emotion_val_human.csv\"\n",
    "table_val.to_csv(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c54c4f3-1f66-4c29-9a18-46ef50f3be62",
   "metadata": {},
   "source": [
    "After modifying the above cell, your `<shortname>_val_human.csv` should be saved to the `project_final` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00530b8a-1cf4-4577-8548-62772ef24778",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Option 2: Upload a CSV from a spreadsheets program\n",
    "\n",
    "Depending on how you and your partner decide to individually code results, you may find it useful to use a spreadsheet program, e.g., Google Spreadsheets.\n",
    "\n",
    "1. Download the `<shortname>_val_uncoded.csv`.\n",
    "1. Upload it to Google Spreadsheets.\n",
    "1. Make two tabs, one for each partner. Fill in codes. Don't peek at each other's work.\n",
    "1. Make one sheet with two new columns labeled `humanA` and `humanB`.\n",
    "1. File --> Download  --> Comma Separated Values (.csv). Rename the file to `<shortname>_val_human.csv`.\n",
    "1. Upload into DataHub by dragging the file into the DataHub File Explorer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62625b66-875e-4846-8c75-3dfef8de7293",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 8: Inter-Reliability Agreement\n",
    "\n",
    "Report Cohen’s Kappa ($\\kappa$) as a measure of the agreement between **you and your partner’s hand-coded labels**. Additionally, use the [Data 6 Notes](https://data6.org/notes/20-coding/cohens-kappa.html#cohens-kappa-as-a-measure-of-inter-rater-agreement) to report the agreement level based on your computed κ.\n",
    "\n",
    "Notes:\n",
    "* We have provided some starter code to compute Cohen’s Kappa below. It uses the `cohen_kappa_score` function from the `sklearn` library.\n",
    "* It is okay to report low $\\kappa$/agreement level in this part. This part is graded on completion.\n",
    "* We are **not** comparing your codes to the human gold standard; for that we will need the F1 score. We explore this in Part B of the assignment.\n",
    "\n",
    "Complete this part by writing code to compute Cohen’s Kappa ($\\kappa$) in the cell below. Then, in your report, report $\\kappa$ **and** the agreement level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aba5c119-051e-4080-8cbf-1e588dbc9770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit the below code as needed\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "human_fname = \"emotion_val_human.csv\" # replace this line\n",
    "\n",
    "human_codes = Table.read_table(human_fname)\n",
    "kappa = cohen_kappa_score(human_codes.column(\"humanA\"), human_codes.column(\"humanB\"))\n",
    "kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31779090-6e0b-4e95-8276-5eca388c1f07",
   "metadata": {},
   "source": [
    "# Done!!!\n",
    "\n",
    "You should download a ZIP of this folder, which should include this notebook AND the `<shortname>_val_human.csv` file you created in Part 3. Read the [Google Doc](https://docs.google.com/document/d/11fLAJmCwJT55pWUVhHQQ2YXkPtPcGrH7Bmn0DBWM85M/edit?usp=sharing) for submission instructions. \n",
    "\n",
    "Part B to be released soon!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
