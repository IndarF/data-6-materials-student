{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede69ab0-dd24-4f17-b9b9-91c1dffea462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell, don't change anything.\n",
    "from datascience import *\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bc1619-4ac6-4d0f-b02f-45e21ca861cf",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "\n",
    "# Project Part B: Introduction\n",
    "\n",
    "The full specification for this project is in Google Docs:\n",
    "* [Final Project: Part A](https://docs.google.com/document/d/11fLAJmCwJT55pWUVhHQQ2YXkPtPcGrH7Bmn0DBWM85M/edit?usp=sharing)\n",
    "* [**Final Project: Part B**](https://docs.google.com/document/d/1xT-5wWedzn2U85U3GpnE40SFskxX-hNzwOGc67Asw8o/edit?usp=sharing)\n",
    "\n",
    "The full description of each dataset is in Google Docs:\n",
    "* [CSS Tasks](https://docs.google.com/document/d/1gWbpm0qHUWHySuj9rq2gl1CvN9BgcQDUQLTl2hYLlsk/edit?usp=sharing)\n",
    "\n",
    "This Jupyter notebook contains code cells that should accompany your Final Project Part B PDF submission. You should submit this notebook (and associated files). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b1a3ae-f4b5-4e56-8454-a5b8176dd487",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Gemini Setup: Installation, API Key\n",
    "\n",
    "Run this section before running question cells. \n",
    "\n",
    "1. In `api_key.py`, set `my_client_access_token` to be the Gemini API key that we shared with you through email. Follow the corresponding instructions in the [Data 6 Notes](https://data6.org/notes/18-html/genius.html) to navigate to the `api_key.py` file and edit it.\n",
    "\n",
    "2. After you have updated `api_key.py` (the file within this assignment directory), running the below cells should install Google Python packages, load your API token into `GOOGLE_API_KEY`, and create a Gemini Client.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "_**Important Note**_:\n",
    "\n",
    " Please DO NOT share your API key outside of this class. We will disable your API key (1) if you misuse it and/or exceed the free usage tier during the project, and (2) for all students after the semester has ended. If you'd like to play around with your code after the term, you'll have to get your own API key. Ask us how to do this!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbea0d4-d7a1-44c2-9b15-3fd15edcc1af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "!pip install google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa4b7be-15a4-4551-8e48-c7461e910344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before running this cell, make sure that you have updated api_key.py with your API key\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import api_key\n",
    "GOOGLE_API_KEY = api_key.my_client_access_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af32c5e-cd52-4332-a703-1df90dedc77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell. it makes a small API request for testing.\n",
    "from google import genai\n",
    "\n",
    "# first, create the client\n",
    "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# then make the API request\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=\"Explain how AI works in a few words\"\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f97df09-c92d-4cd2-800e-ee97ec820d59",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "\n",
    "# Part 1: Zero-Shot Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02590e7-90b7-4476-a858-4728749f9d68",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 1: Task Shortname\n",
    "\n",
    "No code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3aadd7-ebcb-4249-b262-4c1d06c2c188",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 2: Zero-shot Prompt Engineering\n",
    "\n",
    "Develop a zero-shot prompt to code (i.e., label/categorize) the 30 records in `<shortname>_val_uncoded.csv` using an LLM, where <shortname> is the shortname of your CSS task. Then, use Gemini's Python API to directly query the Gemini 2.5 Flash model with this prompt to generate AI-assisted codes, one per record in your dataset.\n",
    "\n",
    "To avoid threats to validity, your zero-shot prompt should **not** include direct references any \"gold labels.\". Additionally, you should **not** include any direct references to the Coding Strategy you developed for human-coding in Part A. The goal is to write a prompt as close as possible to the one described in Ziems et al.\n",
    "\n",
    "Additional prompting guidelines:\n",
    "* Gemini API: Prompting Strategies\n",
    "* Ziem et al., Table 1: LLM Prompting Guidelines to generate consistent, machine-readable outputs for CSS tasks.\n",
    "* We strongly recommend that your prompt includes formatting instructions to cleanly output one code per record per line, so that you can quickly process these codes later. Some suggested ways to end prompts:\n",
    "    * Provide me a CSV table of <A>, <B>, and <C>, where <A is…>, … . Ensure the output is a CSV table with three columns.\n",
    "    * Provide an array of JSON objects with keys <A>, <B>, and <C>. <A is…>, … . Ensure the output is a JSON array of objects.\n",
    "    * Provide me a list of <C>, where <C is …>, … Ensure the output is a list of … separated by newlines.\n",
    "\n",
    "In the cells below, write code to make the appropriate API call. Some starter code is provided for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd6570d-5f86-4c18-8257-aed7601c7d2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# edit these lines as needed\n",
    "\n",
    "csv_fname = \"datasets/emotion_val_uncoded.csv\"\n",
    "table_val_uncoded = Table.read_table(csv_fname)\n",
    "arr = table_val_uncoded.column(\"text\")\n",
    "\n",
    "input_records = '\\n'.join(arr)\n",
    "print(input_records[:500]) # some preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee75532d-16c4-4c37-82e0-950862b0bed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit these lines as needed\n",
    "\n",
    "prompt = \"\"\"Count the number of lines provided below. Return an integer.\"\"\"\n",
    "prompt_coda = \"\"\"Make sure to format your output as an integer.\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=[\n",
    "        prompt,\n",
    "        '\\n',\n",
    "        input_records,\n",
    "        '\\n',\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac974a9d-352e-4030-8846-8fd5e3a78eda",
   "metadata": {},
   "source": [
    "Then, in your Google Doc report, report your custom prompt, omitting input records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad72f64a-4605-4360-9871-d888b458da23",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 3: Export all codes to a CSV\n",
    "\n",
    "In the cell below, use Gemini's Python API to directly query the **Gemini 2.5 Pro model** with the exact prompt you wrote above to generate a second set of AI-assisted codes, one per record in the `<shortname>_val_uncoded.csv`.\n",
    "\n",
    "See how to do this in the GenAI lab. The model name is `\"gemini-2.5-pro\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe415de-0c7d-46c1-9163-60014d56bf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d32322-b542-4a76-8d8e-21d9c9774157",
   "metadata": {},
   "source": [
    "Then, export a new CSV called `<shortname>_val_coded.csv` with all hand-coded and AI-coded labels. **Read the full description of this task (including CSV format) in the Google Doc.**\n",
    "\n",
    "You can create this CSV by building a `datascience` table and saving it directly in DataHub; or by building a spreadsheet in, say, Google Sheets, exporting it to CSV, then uploading it to DataHub. See Final Project A's accompanying Jupyter Notebook (Part A.3) for how to do this.\n",
    "\n",
    "Regardless of which approach you use, you may find it useful to use `datascience` Table methods to first find the corresponding gold labels for your records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f93efb-3343-4fb0-a800-5e4721e2b5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81ce7c6-205e-4969-b175-f75a25bb2c26",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 4: Evaluate Performance Quantitatively\n",
    "\n",
    "Compare the performance of these four strategies (two hand-coded, two AI-coded) by computing Cohen’s Kappa ($\\kappa$) with respect to the human gold labels. Note that the human gold labels can still be unreliable, so computing Cohen’s Kappa is still applicable.\n",
    "\n",
    "Notes:\n",
    "* We have provided some starter code to compute Cohen’s Kappa from the appropriate functions in the sklearn library. It uses the `cohen_kappa_score` function from the `sklearn` library. It assumes that you have correctly labeled and uploaded the CSV file in the previous part.\n",
    "* It is okay to report low κ/agreement level in this part. This part is graded on completion.\n",
    "* For each of the four strategies, $\\kappa$ should be computed with respect to the human gold labels.\n",
    "\n",
    "Complete this part by writing code to compute Cohen’s Kappa ($\\kappa$) for each strategy in the cell below. Then, in your report, report the $\\kappa$ **and** agreement level for each strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871f0212-85fc-4f74-88ce-1192ed25c821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit the below code as needed\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# replace the below lines\n",
    "# depending on where you uploaded it, could be \"datasets/<filename>.csv\"\n",
    "coded_fname = \"emotion_ai.csv\" # replace this line\n",
    "gold_label = \"emotions\" # replace this with the name of your gold label column\n",
    "\n",
    "table_codes = Table.read_table(coded_fname)\n",
    "\n",
    "# you should write additional code to compute kappa for other strategies\n",
    "kappa_human_A = cohen_kappa_score(table_codes.column(\"Gemini 2.5 Flash\"),\n",
    "                                  table_codes.column(gold_label))\n",
    "print(\"human_A\", kappa_human_A)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aba8e3b-0783-4515-83e5-61605edb3d21",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 5: Evaluate Performance Qualitatively\n",
    "\n",
    "No code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1180ef49-0a77-45b1-a8e5-3accb2926a12",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "\n",
    "# Part 2: Context-Based, Few-Shot Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802fa0ed-0e84-45d7-b0be-20e84b6802e7",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 6: Few-Shot Prompt Engineering\n",
    "\n",
    "Develop a prompt to code (i.e., label/categorize) all records in `<shortname>.csv` using an LLM. Your prompt should include examples drawn from the example records in `<shortname>_train.csv`.\n",
    "\n",
    "Notes:\n",
    "* We suggest that your prompt include some of the examples provided in `<shortname>_train.csv`, including gold labels. You can also consider including components of your hand-coder Coding Strategy you developed in Part A.\n",
    "    * To avoid threats to validity, your prompt should not include any direct references to other gold labels in the full `<shortname>.csv` dataset. \n",
    "* Important: We strongly **advise against** making one giant API request to code the entire dataset; your prompt will likely lose context quickly and make mistakes, and the request will be costly (both price-wise and time-wise).\n",
    "    * Instead, choose a reasonable subset, e.g., **30 or 50 records**, to iterate rapidly through a good prompt.\n",
    "    * Then construct the full set of dataset codes in the next question.\n",
    "* You should complete this part using **Gemini 2.5 Flash**. Do **not** use Gemini 2.5 Pro; it is costly and will generate response times that are untenable for some tasks.\n",
    "\n",
    "In the cells below, write code to make the appropriate API call. Some starter code is provided for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7925ef6e-a9ed-4985-9fea-f93f0674ee68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit these lines as needed\n",
    "# pulls small amount of records (e.g., 30) from the full dataset\n",
    "\n",
    "csv_fname = \"datasets/emotion.csv\"\n",
    "table_uncoded = Table.read_table(csv_fname)\n",
    "arr = table_uncoded.column(\"text\")\n",
    "tiny_arr = arr[:30] # small amount of records\n",
    "\n",
    "input_records = '\\n'.join(tiny_arr)\n",
    "print(tiny_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9712d693-e897-438c-a10e-0453ed545cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit these lines as needed\n",
    "\n",
    "prompt = \"\"\"Count the number of lines provided below. Return an integer.\"\"\"\n",
    "prompt_coda = \"\"\"Make sure to format your output as an integer.\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=[\n",
    "        prompt,\n",
    "        '\\n',\n",
    "        input_records,\n",
    "        '\\n',\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2785faed-ad8b-45a8-a64c-da67fa23492e",
   "metadata": {},
   "source": [
    "Then, in your Google Doc report, report your custom prompt, omitting input records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb383dfa-8438-4cb6-be1b-340611c4aa03",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 7: Export all codes to a CSV\n",
    "\n",
    "Use Gemini’s Python API to directly query the Gemini 2.5 Flash model with the exact prompt you wrote above to generate a full set of AI-assisted codes for `<shortname>.csv`, one per record in your dataset. \n",
    "\n",
    "This question is challenging because you will need to design a strategy that will work for large sets of data—involving multiple API requests. But you will be able to do this task with the tools you have in this class. If you get stuck, definitely come by office hours or make an Ed post!!!\n",
    "\n",
    "**Hints/Notes:** \n",
    "\n",
    "* This question is intentionally open-ended. That being said, see our recommended strategy below, and heed the following:\n",
    "    * As above, we strongly advise against making one giant API request to code the entire dataset. Instead, **loop through** all records and iteratively code each subset of records. We recommend a subset size like 30 or 50.\n",
    "    * Recall that with the Gemini API, the argument to contents can be a list of strings. In each iteration of your loop, you may find it useful to build a new list that includes your prompt string from before and a new subset of records to code (as a string).\n",
    "    * Some of your datasets may be up to 20,000 records—this means that any loop will run **for a long time**, with or without prompting!\n",
    "* It is alright to use Generative AI for this question, but you will be expected to understand your approach. Depending on your approach, during grading we may ask you follow-up questions about your code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40732e48-eb47-41bf-913c-e2421cae7bda",
   "metadata": {},
   "source": [
    "**Recommended strategy**:\n",
    "\n",
    "1. Build the loop structure for a small part of your data, say, 500 records at most.\n",
    "    1. First, write a loop that iterates through the subsets of records in your data. We recommend print-ing the length of these subsets, or the IDs, just as a sanity check. Let’s assume your subset has 50 records, so your loop should run 10 times.\n",
    "    1. Next, add code to your loop that iteratively builds an array or list of outputs with each iteration. This will simulate the API response outputs that you will need to save with each iteration.\n",
    "        * We recommend saving “dummy” values for now, just to check that everything works.\n",
    "        * Additionally, we recommend just creating this array, then cleaning/post-processing in a different cell. See below.\n",
    "    1. Then, add code to your loop that builds the right contents list that incorporates the prompt for each iteration. print out contents list each iteration to double check it looks right.\n",
    "    1. Finally, add code to your loop that makes the API call.\n",
    "1. Run and check that the loop structure works for this 500 records. It may take a few minutes.\n",
    "1. After you have your list of outputs, in a separate cell post-process the outputs, e.g., split into lines, make into an array, make into a column, save into the right CSV format, etc. Keeping the API calls into a separate cell, avoids you having to run all of the API calls again just to do some string manipulation.\n",
    "1. After you’ve verified that both your prompting **and** exporting cells work for the 500-record case, then edit your loop to run on the *entire dataset*.\n",
    "    * If your dataset is not a clean multiple of your 50-record chunk, consider letting your loop deal with the general case, then separately process the last few records outside of the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da814cfd-ef41-4c59-bf46-8dd6296ff035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3520523-dfb7-4247-9017-e2f56ff9fe77",
   "metadata": {},
   "source": [
    "Then, export this set of code labels to a new CSV labeled `<shortname>_ai.csv`, where `<shortname>` is the shortname of your CSS task. **Read the full description of this task (including CSV format) in the Google Doc.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702bb63f-d8ad-457b-9460-edfda8da6b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code cell if you need it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c56ca6f-b45a-42ef-b2d7-b184dadff475",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 8: Evaluate Performance Quantitatively\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2e84d7-6d45-4471-afed-b4e14dfd7ba5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Question 8a: Cohen’s Kappa\n",
    "\n",
    "Evaluate the performance of this AI-coding strategy by computing Cohen’s Kappa (κ) with respect to the **human gold labels**. Note that like before, the human gold labels can still be unreliable, so computing Cohen’s Kappa is still applicable.\n",
    "\n",
    "Complete this part by writing code to compute Cohen’s Kappa ($\\kappa$) below; we've filled out some parts for you. Then, in your report, report the $\\kappa$ **and** agreement level for each strategy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049fb010-baff-454f-a807-20bd3ad04c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit the below code as needed\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# replace the below lines\n",
    "# depending on where you uploaded it, could be \"datasets/<filename>.csv\"\n",
    "coded_fname = \"emotion_ai.csv\" # replace this line\n",
    "gold_label = \"emotions\" # replace this with the name of your gold label column\n",
    "\n",
    "\n",
    "\n",
    "table_codes = Table.read_table(coded_fname)\n",
    "kappa = cohen_kappa_score(table_codes.column(\"Gemini 2.5 Flash\"),\n",
    "                                  table_codes.column(gold_label))\n",
    "print(kappa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd381897-76a5-4663-8c9d-eeab7b1c9706",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "\n",
    "### [Tutorial] Visualizing a Confusion Matrix\n",
    "\n",
    "Below, we have provided some starter code that first computes a small confusion matrix with the sklearn method confusion_matrix [[sklearn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)] then visualizes this matrix as a heatmap [[seaborn documentation](https://seaborn.pydata.org/generated/seaborn.heatmap.html)]. Feel free to start from this as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6bf16b-dc25-4cc7-bcfb-24557911f71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = [\"cat\", \"ant\", \"cat\", \"cat\", \"ant\", \"bird\"]   # gold/standard labels\n",
    "y_pred = [\"ant\", \"ant\", \"cat\", \"cat\", \"ant\", \"cat\"]    # \"AI\"/predicted labels\n",
    "labels = [\"ant\", \"bird\", \"cat\"] # categorical variable values, the order of entries in the resulting matrix\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true, y_pred, labels=labels) # a 2-D matrix!\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864ed7aa-927b-463e-951c-3a43c82afea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "import seaborn as sns\n",
    "ax = sns.heatmap(conf_matrix,\n",
    "                 cmap=\"YlOrBr\",\n",
    "                 xticklabels=labels,\n",
    "                 yticklabels=labels,\n",
    "                 annot=True,\n",
    "                 annot_kws={\"fontsize\":20}\n",
    "                )\n",
    "\n",
    "# add x labels, change font size of x tick labels\n",
    "ax.set_xlabel(\"Predicted labels\")\n",
    "ax.set_xticklabels(ax.get_xmajorticklabels(), fontsize=10)\n",
    "\n",
    "# add y labels, change font size of y tick labels\n",
    "ax.set_ylabel(\"Gold labels\")\n",
    "ax.set_yticklabels(ax.get_ymajorticklabels(), fontsize=10)\n",
    "ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33c9bd6-dbe1-48f2-88f4-d9fc2142cbe8",
   "metadata": {},
   "source": [
    "\n",
    "<br></br>\n",
    "\n",
    "---\n",
    "    \n",
    "### Question 8b: Confusion Matrix \n",
    "\n",
    "Evaluate the performance of this AI-coding strategy by computing the confusion matrix of the AI-coded labels and the human gold labels. Feel free to start from the example above.\n",
    "\n",
    "In the cell below, write code that produces a visualization. We've copied over the relevant code; just modify the code where indicated to load in the correct columns of your `<shortname>_ai.csv` data. Remember, `tbl.column(colname)` returns the `colname` column of `tbl` as an array.  Set `y_true`, `y_pred` accordingly. You may need to manually input the categorical values of your label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb74d5b9-0452-4bbf-829d-0e4fc68eae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# edit this block of code\n",
    "csv_fname = ...\n",
    "table = Table.read_table(csv_fname)\n",
    "\n",
    "y_true = table.column(...)   # gold/standard labels\n",
    "y_pred = table.column(...)   # \"AI\"/predicted labels\n",
    "labels = [..., ..., ]   # categorical variable values, the order of entries in the resulting matrix\n",
    "\n",
    "# make minimal changes below this line\n",
    "# only tweak color and formatting if needed\n",
    "ax = sns.heatmap(conf_matrix,\n",
    "                 cmap=\"YlOrBr\",\n",
    "                 xticklabels=labels,\n",
    "                 yticklabels=labels,\n",
    "                 annot=True,\n",
    "                 annot_kws={\"fontsize\":20}\n",
    "                )\n",
    "\n",
    "# add x labels, change font size of x tick labels\n",
    "ax.set_xlabel(\"Predicted labels\")\n",
    "ax.set_xticklabels(ax.get_xmajorticklabels(), fontsize=10)\n",
    "\n",
    "# add y labels, change font size of y tick labels\n",
    "ax.set_ylabel(\"Gold labels\")\n",
    "ax.set_yticklabels(ax.get_ymajorticklabels(), fontsize=10)\n",
    "ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56edd6c0-50ac-4dc2-9bc5-84b3fd7a0778",
   "metadata": {},
   "source": [
    "Then, in your Google Doc report, include screenshot(s) of the resulting confusion matrix. You do not need to screenshot your code; writing your code in the cell below is sufficient.\n",
    "\n",
    "Finally, in your Google Doc report, report the overall accuracy of the class accuracies (one per label in your categorical variable) of your AI codes. \n",
    "\n",
    "An additional code cell is provided for you below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e48c68-c29f-4cb2-8926-aa4ec840d8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here, if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa45def-837a-454e-a0a1-3b17a129b174",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 9: Evaluate Performance Qualitatively\n",
    "\n",
    "No code.\n",
    "\n",
    "If you need it, the below cell samples a few rows from your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b82aaaa-1eb1-4483-9d6e-91358334ad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# depending on where you uploaded it, could be \"datasets/<filename>.csv\"\n",
    "all_coded_fname = \"emotion_ai.csv\" # replace this line\n",
    "\n",
    "all_table = Table.read_table(all_coded_fname)\n",
    "\n",
    "# sample 10 rows of your dataset, with no repeats. Take Data 8 for more!\n",
    "all_table.sample(10, with_replacement=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2e5cc9-6ea8-49bd-8ba7-36b3f2de5f9b",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 10: Reflect\n",
    "\n",
    "No code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31779090-6e0b-4e95-8276-5eca388c1f07",
   "metadata": {},
   "source": [
    "# Done!!!\n",
    "\n",
    "You should download a ZIP of this folder, which should include this notebook, the `<shortname>_val_coded.csv` file you created in Part B.1, and the `<shortname>_ai.csv` file you created in part B.2. Read the [Google Doc](https://docs.google.com/document/d/1xT-5wWedzn2U85U3GpnE40SFskxX-hNzwOGc67Asw8o/edit?usp=sharing) for submission instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
